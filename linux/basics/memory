I- Hardware

Memory Zones (for 64-bit processors)
DMA    (first 16MB of memory 24-bit I/O)
DMA32  (16MB to 4GB 32-bit I/O)
Normal (4GB to end of RAM...)


II- Memory Fragmentation and Compaction

/proc/buddyinfo expose fragmenetation (simplified output)

               Order             0       1      2      3      4      5      6      7      8      9     10 
               Zone 4k Pages     1       2      4      8     16     32     64    128    256    512   1024
               Zone Byte Size  4kB     8kB   16kB   32kB   64kB  128kB  256kB  512kB 1024kB 2048kB 4096kB
                        |                                                                                |   
Node         Zone name  |                                                                                |
------------------------+--------------------------------------------------------------------------------+
Node 0, zone      DMA   |       3       2      2      2      2      1      0      0      1      1      3 |
Node 0, zone    DMA32   |    8774    4785   2383   1472   1102    840    606    377    190    139     19 |
Node 0, zone   Normal   |  147104  336891 113434 136648  72075  29349   9539   3304   1481    727      0 |
Node 1, zone   Normal   | 1211026 1381111 482960  82119   7636    924    186     83    283      1      0 |

/proc/pagetypeinfo file classify these pages by type (Unmovable,Reclaimable,Movable,Reserve,Isolate)

/proc/zoneinfo 

Physical memory available in MB:
echo $(($(getconf _PHYS_PAGES) * $(getconf PAGE_SIZE) / (1024 * 1024)))

Virtual memory available in MB:
echo $(($(getconf _AVPHYS_PAGES) * $(getconf PAGE_SIZE) / (1024 * 1024)))

Compaction
All zones can be compacted such that free memory is available in contiguous blocks where possible by:

echo 1 > /proc/sys/vm/compact_memory 

# Documentation in /usr/share/doc/kernel-doc-<kernel-version>/Documentation/filesystems/proc.txt
Per Proocess Memory statictics in /proc/<pid>/stat
                                  /proc/<pid>/statm
                                  /proc/<pid>/status E.g: VmSize, VmRSS = RssAnon + RssFile + RssShmem ,VmPTE(pid page table size )

PageTables size in /proc/meminfo 

Note: pidstat command can be used also

III- HugePages and Transparent Huge Pages (THP)

1- HugePages
# Documentation in /usr/share/doc/kernel-doc-<kernel-version>/Documentation/vm/hugetlbpage.txt
/proc/meminfo 

PageTables:       1244880 kB
HugePages_Total:      0
HugePages_Free:       0
HugePages_Rsvd:       0
HugePages_Surp:       0
Hugepagesize:       2048 kB

HugePages_Total: Number of hugepages : sysctl vm.nr_hugepages= or /proc/sys/vm/nr_hugepages .
HugePages_Rsvd : Number of hugepages committed to be allocated by application but no allocation has yet been made.
                 (Garuante that an application will be able to allocate a huge page at fault time)
HugePages_Surp : Number of hugepages surplus above vm.nr_hugepages : /proc/sys/vm/nr_overcommit_hugepages.
HugePages_Used = HugePages_Total - HugePages_Free 

In order to set hugepages  : sysctl -w vm.nr_hugepages=xx or vm.nr_hugepages=xx in /etc/sysctl.conf at boot time
      
Note: Restart the system after configuring hugepages for chances of having free contiguous memory.

Kernel commandline  : default_hugepagesz =  default huge page size
                      hugepagesz         = 2MB/1GB
                      hugepages          = number of pages of pervious hugepagesz 

vm.nr_overcommit_hugepages : number of huge pages from normal page if huge page exhausted. 

Hugepages File System (hugetlbfs)
In case application use mmap system call hugepages must be mounted :

mount -t hugetlbfs none /largepage 

Notes: 
-Hugepages are not swappable
-Application uses only shmat and shmget no hugetlbfs
-Application only need to be run by user with GID in  /proc/sys/vm/hugetlb_shm_group

2- THP

Enable/Disable at Runtime  /sys/kernel/mm/transparent_hugepage/enabled
 always  : enabled 
 madvise : disable hugepages system-wide only in madvise regions
 never   : disabled 

Disable at boot
Kernel commandline : transparent_hugepage=never|always|madvise

Defragmentation /sys/kernel/mm/transparent_hugepage/defrag
always  : enabled
madvise : defrag only in madvise regions
never   : disbaled regular pages served
Zero Huge Pages /sys/kernel/mm/transparent_hugepage/use_zero_page
0   : enable
1   : disable

khugepaged /sys/kernel/mm/transparent_hugepage/khugepaged 
Kernel thread occasionally attempt to substitute smaller pages being used currently with a hugepage allocation,
thus maximizing THP usage.

THP usage 

System-Wide :
/proc/meminfo label : AnonHugePages since file-based hugepages are not supported

Per Process :
grep -e AnonHugePages  /proc/*/smaps | awk  '{ if($2>4) print $0} ' |  awk -F "/"  '{print $0; system("ps -fp " $3)} '

IV- SWAP

SWAP is disk space used in case of memory pressure to swap-out pages, it can be a partition or a file
It's better to swap out a program that's been inactive for a while, and instead keep often-used files in cache (inactive memory).

swapon -s
Filename  Type            Size       Used Priority
/dev/sdd  partition/file   KB        -1(Default) ... 32767 (Highest) 

Note: two swap space with same priority treated in round-robin way increasing swap performance.

Create SWAP partition

1) fdisk /dev/sdd ; n : create partition ; t : change partition system id to 82 (Linux swap / Solaris)
2) mkswap /dev/sdd 
3) swapon /dev/sdd -p 1 
4) add entries in /etc/fstab : /dev/sdd none swap sw,pri=1 
5) turn off all swap space : swapoff -a
6) mounts all swap spaces in /etc/fstab : swapon -a 

Create SWAP file
1) dd if=/dev/zero of=/tmp/swap_file bs=1024 count=1048576
2) mkswap /tmp/swap_file
3) swapon /tmp/swap_file

Control SWAPINESS
Degree to which the system favors anonymous memory or the page cache.

vm.swappiness=<0..100> /proc/sys/vm/swappiness (Default 60)

swappiness=0      aggressively avoids swapping out (increases OOM risk under strong memory and I/O pressure).
swappiness=<high> aggressively swapping less active processes out of physical memory.
swappiness=<low>  avoids swapping processes out of memory (decreases latency).

V- Memory Over Commitement
Linux provisions more memory (both RAM and Swap) than it has available. 

overcommitt parameters : sysctl vm.overcommit_memory : /proc/sys/vm/overcommit_memory
                         sysctl vm.overcommit_ratio  : /proc/sys/vm/overcommit_ratio

vm.overcommit_memory : 
0 = heuristic overcommit (1/33 ~ 3% of free reserved for root)
1 = always overcommit 
2 = strict overcommit limited by overcommit_ratio. ( CommitLimit in /proc/meminfo) (1/32 ~ 3% of real memory reseverd for root)

vm.overcommit_ratio:
Memory Allocation Limit = Swap + RAM * (Overcommit Ratio / 100)

Committed_AS in /proc/meminfo : committed address space,an estimate RAM needed to never have OOM.

Note: If overcommit_memory = 2 ,always check the overcommit_ratio in case of RAM add or SWAP remove.
Overcommit Ratio = 100 * ((RAM - Swap Space) / RAM)

VI- OOM
Out of Memory  killer is kicking in is purely based on the availability of free pages. 
This could be a page alloc failure from any memory zones

vm.panic_on_oom = enables/disables oom_killer.
                = 0 enabled
                = 1 kernel panic 
                = 2 kernel panic for cgroups (+kdump)

vm.oom_kill_allocating_task = specify task for OOM to kill
                            = 0 heuristic : rogue memory-hogging task
                            = <pid>       : task to oom

/proc/<PID>/oom_score     : OOM score ,the higher value the likely <PID> OOM killer.(kernel and systemd are immune)
/proc/<PID>/oom_adj       : determine oom score = -17     disbale oom_killer
                                                =   0     no change (default)  
                                                = -16..15 multiply oom_score * 2 ^ oom_adj
/proc/<PID>/oom_score_adj : adjust oom score (add the value) 
                            -1000 ... 1000

force the OOM killer      :  echo f > /proc/sysrq -trigger highest oom_score process will be killed.

VII- Memory Reclamition
#
1) Buffer :

vm.dirty_expire_centisecs    : age in 1/100th of a sec the dirty pages must be before flushing to disk.
vm.dirty_writeback_centisecs : kernel BDI-flush thread frequency
vm.dirty_background_ratio    : % dirty memory before sync.
vm.dirty_ratio               : % dirty memory before block all writes IO and sync.
vm.min_free_kbytes           : force VM to keep a minimum amount of memory free (KiB)

2) Cache :
See fs

VIII- IPC
Inter-Process-Communication are mechanisms provided by the kernel to allow processes to communicate with each other.
These are the six primary IPC mechanisms available:

1- Sockets       : Unix Domain Socket (*) (NETLINK ,NETWORK) TCP/IP or UDP sockets to exchange data over the sockets.
2- Pipes         : pipe is used for one way communication of a stream of bytes.
3- Shared Memory : allows one process to share a region of memory in its address space with another. (fastest no  kernel intervention)
4- Semaphores    : locking and synchronization mechanism used most widely when processes share resources.
5- Message Queues: one or more processes can write messages, which can in turn be read by one or more reading processes.
6- Signals       : used to signal asynchronous events to one or more processes (oldest IPC used by Unix systems)

Redhat has 3 methods : Shared Memory, Semaphores, and Message Queues.

kernel parameter
Shared Memory
kernel.shmmax  : /proc/sys/kernel/shmmax : the max allowable size of one shared memory segment in bytes
kernel.shmmni  : /proc/sys/kernel/shmmni : the max number of shared memory segments in the entire system
kernel.shmall  : /proc/sys/kernel/shmall : the max size of shared memory in pages (one page = 4096 bytes for x86/x86_64)

Semaphore
kernel.sem     : /proc/sys/kernel/sem	<SEMMSL> <SEMMNS> <SEMOPM> <SEMMNI>
SEMMSL	the max number of semaphores per identifier/array
SEMMNS	the max number of semaphores system wide
SEMOPM	the max number of operations per semaphore call
SEMMNI	the max number of semaphore arrays 

Message Queue
kernel.msgmni /proc/sys/kernel/msgmni	: the number of message queue identifiers
kernel.msgmax /proc/sys/kernel/msgmnb	: the default max size of a message queue in bytes
kernel.msgmnb /proc/sys/kernel/msgmax	: the max size of a message in bytes

ipcmk, ipcs, ipcrm : tools to manuapilite System V interprocess communication (IPC)

ipcmk : create shared memory segment (-M), a semaphore (-S), or a message queue (-Q)
ipcs  : list shared memory segment (-m), a semaphore (-s), or a message queue (-q)
        list limits (-l)
        list pids   (-p)
ipcrm : remove shared memory segment (-m), a semaphore (-s), or a message queue (-q)

kernel.threads-max : system-wide maximum number of threads at one time.

(*)
Unix domain sockets (UDS) create a file on the file system for communication

