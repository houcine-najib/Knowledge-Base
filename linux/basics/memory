I- Hardware

Memory Zones (for 64-bit processors)
DMA    (first 16MB of memory 24-bit I/O)
DMA32  (16MB to 4GB 32-bit I/O)
Normal (4GB to end of RAM...)


II- Memory Fragmentation and Compaction

/proc/buddyinfo expose fragmenetation (simplified output)

               Order             0       1      2      3      4      5      6      7      8      9     10 
               Zone 4k Pages     1       2      4      8     16     32     64    128    256    512   1024
               Zone Byte Size  4kB     8kB   16kB   32kB   64kB  128kB  256kB  512kB 1024kB 2048kB 4096kB
                        |                                                                                |   
Node         Zone name  |                                                                                |
------------------------+--------------------------------------------------------------------------------+
Node 0, zone      DMA   |       3       2      2      2      2      1      0      0      1      1      3 |
Node 0, zone    DMA32   |    8774    4785   2383   1472   1102    840    606    377    190    139     19 |
Node 0, zone   Normal   |  147104  336891 113434 136648  72075  29349   9539   3304   1481    727      0 |
Node 1, zone   Normal   | 1211026 1381111 482960  82119   7636    924    186     83    283      1      0 |

/proc/pagetypeinfo file classify these pages by type (Unmovable,Reclaimable,Movable,Reserve,Isolate)

/proc/zoneinfo 

Physical memory available in MB:
echo $(($(getconf _PHYS_PAGES) * $(getconf PAGE_SIZE) / (1024 * 1024)))

Virtual memory available in MB:
echo $(($(getconf _AVPHYS_PAGES) * $(getconf PAGE_SIZE) / (1024 * 1024)))


Compaction
All zones can be compacted such that free memory is available in contiguous blocks where possible by:

echo 1 > /proc/sys/vm/compact_memory 

III- HugePages and Transparent Huge Pages (THP)

1- HugePages
/proc/meminfo 

PageTables:       1244880 kB
HugePages_Total:      0
HugePages_Free:       0
HugePages_Rsvd:       0
HugePages_Surp:       0
Hugepagesize:       2048 kB

HugePages_Total: Number of hugepages : sysctl vm.nr_hugepages= or /proc/sys/vm/nr_hugepages .
HugePages_Rsvd : Number of hugepages committed to be allocated by application but no allocation has yet been made.
                 (Garuante that an application will be able to allocate a huge page at fault time)
HugePages_Surp : Number of hugepages surplus above vm.nr_hugepages : /proc/sys/vm/nr_overcommit_hugepages.
HugePages_Used = HugePages_Total - HugePages_Free 

In order to set hugepages  : sysctl -w vm.nr_hugepages=xx or vm.nr_hugepages=xx in /etc/sysctl.conf at boot time
      
Note: Restart the system after configuring hugepages for chances of having free contiguous memory.

Kernel commandline  : hugepages= 
                      hugepagesz= 2MB default /hardware dependent
vm.nr_overcommit_hugepages : number of huge pages from normal page if huge page exhausted. 

2- THP

Enable/Disable at Runtime  /sys/kernel/mm/transparent_hugepage/enabled
 always  : enabled 
 madvise : disable hugepages system-wide only in madvise regions
 never   : disabled 

Disable at boot
Kernel commandline : transparent_hugepage=never|always|madvise

Defragmentation /sys/kernel/mm/transparent_hugepage/defrag
always  : enabled
madvise : defrag only in madvise regions
never   : disbaled regular pages served
Zero Huge Pages /sys/kernel/mm/transparent_hugepage/use_zero_page
0   : enable
1   : disable

khugepaged /sys/kernel/mm/transparent_hugepage/khugepaged 
Kernel thread occasionally attempt to substitute smaller pages being used currently with a hugepage allocation,
thus maximizing THP usage.

THP usage 

System-Wide :
/proc/meminfo label : AnonHugePages since file-based hugepages are not supported

Per Process :
grep -e AnonHugePages  /proc/*/smaps | awk  '{ if($2>4) print $0} ' |  awk -F "/"  '{print $0; system("ps -fp " $3)} '

IV- SWAP

SWAP is disk space used in case of memory pressure to swap-out pages, it can be a partition or a file
It's better to swap out a program that's been inactive for a while, and instead keep often-used files in cache (inactive memory).

swapon -s
Filename  Type            Size       Used Priority
/dev/sdd  partition/file   KB        -1(Default) ... 32767 (Highest) 

Note: two swap space with same priority treated in round-robin way increasing swap performance.

Create SWAP partition

1) fdisk /dev/sdd ; n : create partition ; t : change partition system id to 82 (Linux swap / Solaris)
2) mkswap /dev/sdd 
3) swapon /dev/sdd -p 1 
4) add entries in /etc/fstab : /dev/sdd swap swap sw,pri=1 0 0
5) turn off all swap space : swapoff -a
6) mounts all swap spaces in /etc/fstab : swapon -a 

Create SWAP file
1) dd if=/dev/zero of=/tmp/swap_file bs=1024 count=1048576
2) mkswap /tmp/swap_file
3) swapon /tmp/swap_file

Control SWAPINESS
Degree to which the system favors anonymous memory or the page cache.

vm.swappiness=<0..100> /proc/sys/vm/swappiness (Default 60)

swappiness=0      aggressively avoids swapping out (increases OOM risk under strong memory and I/O pressure).
swappiness=<high> aggressively swapping less active processes out of physical memory.
swappiness=<low>  avoids swapping processes out of memory (decreases latency).

V- Memory Over Coommitement
Linux provisions more memory (both RAM and Swap) than it has available. 

overcommitt parameters : sysctl vm.overcommit_memory : /proc/sys/vm/overcommit_memory
                         sysctl vm.overcommit_ratio  : /proc/sys/vm/overcommit_ratio

vm.overcommit_memory : 
0 = heuristic overcommit (1/3 ~ 3% of free reserved for root)
1 = always overcommit 
2 = strict overcommit limited by overcommit_ratio. ( CommitLimit in /proc/meminfo) (1/32 ~ 3% of real memory reseverd for root)

vm.overcommit_ratio:
Memory Allocation Limit = Swap + RAM * (Overcommit Ratio / 100)

Committed_AS in /proc/meminfo : committed address space,an estimate RAM needed to never have OOM.

Note: If overcommit_memory = 2 ,always check the overcommit_ratio in case of RAM add or SWAP remove.

Overcommit Ratio = 100 * ((RAM - Swap Space) / RAM)

VI- OOM

Out of Memory  killer is kicking in is purely based on the availability of free pages. 
This could be a page alloc failure from any memory zones

‚Å†o o m_ad j
In the event that the system runs out of memory and the panic_on_oom parameter is set to
0 , the o o m_ki l l er function kills processes until the system can recover, starting from the
process with the highest o o m_sco re.
The oom_adj parameter helps determine the oom_score of a process. This parameter is
set per process identifier. A value of -17 disables the o o m_ki l l er for that process. Other
valid values are from -16 to 15.

panic_on_oom

This enables or disables panic on out-of-memory feature.

If this is set to 0, the kernel will kill some rogue process,
called oom_killer.  Usually, oom_killer can kill rogue processes and
system will survive.

If this is set to 1, the kernel panics when out-of-memory happens.
However, if a process limits using nodes by mempolicy/cpusets,
and those nodes become memory exhaustion status, one process
may be killed by oom-killer. No panic occurs in this case.
Because other nodes' memory may be free. This means system total status
may be not fatal yet.

If this is set to 2, the kernel panics compulsorily even on the
above-mentioned. Even oom happens under memory cgroup, the whole
system panics.

The default value is 0.
1 and 2 are for failover of clustering. Please select either
according to your policy of failover.
panic_on_oom=2+kdump gives you very strong tool to investigate
why oom happens. You can get snapshot.


oom_kill_allocating_task

This enables or disables killing the OOM-triggering task in
out-of-memory situations.

If this is set to zero, the OOM killer will scan through the entire
tasklist and select a task based on heuristics to kill.  This normally
selects a rogue memory-hogging task that frees up a large amount of
memory when killed.

If this is set to non-zero, the OOM killer simply kills the task that
triggered the out-of-memory condition.  This avoids the expensive
tasklist scan.

If panic_on_oom is selected, it takes precedence over whatever value
is used in oom_kill_allocating_task.

The default value is 0.








When a minor page fault happens, but there are no free pages available, the kernel tries to

reclaim memory to satisfy the request. If it cannot reclaim sufficient memory in a timely manner,

an out-of-memory condition occurs.

By default, a subsystem called the Out-of-Memory Killer (or "OOM killer") will select and kill one

or more processes to free memory so that the request can be satisfied. As an alternative, if the

sysctl tunable vm.panic_on_oom is set to 1instead of 0, the kernel will panic instead.

Note

Once the system has reached a point where it has an out-of-memory condition, there

are not many reasonable options for recovery. Killing a process to free memory, giving

up and killing the system, or deadlock are all possible choices. In general, it is best to

avoid allowing the system to get into an out-of-memory condition if at all possible.

To determine which process the OOM killer should kill, the kernel keeps a running badness

score for every process, which can be viewed in /proc/PJD/oom_score. The higher the score

the more likely the process will be killed by the OOM killer. A number of factors are used to

calculate this score: the VM-size (not RSS size), the cumulative VM size of any children the

process has, nice values (positive nice values give a higher score), total runtime (a longer total

RH442-RHEL7-en-1-20150128 243

Chapter 9.Tuning the Server for Large Memory Workload

runtime will reduce the score), running user (root processes get a slight protection), and if the

process performs direct hardware access, the score is lowered as well. The kernel itself and PID 1

(systemd)are immune from the OOM killer.

Two tunables, /proc/PID/oom_adj and /proc/PI0/oom_score_adj can be used to

manually adjust oom_score.

oom _adj can take values from -17 to 15 where 0 means no change (the default), -17 means

immunity (never kill) and any other value will be used to modify oom_score by multiplying

oom score with 2oom_adj. Therefore, setting a positive oom_adj value makes a process more

likely to be killed, while setting a negative value reduces the chances of being terminated by the

kernel.

Similarly, values put into oom_score_adj are also added to the oom_score.However, the

mechanism for using oom_score_adj is different than oom_adj.oom_score_jadj can be

set to values ranging from -1000 to 1000. When a value is put into oom _score_adj that

value is added to the oom_score.No odd mathematical adjustment is applied. The value in

oom_score_adj is simply added to oom_score.

Note

To force the OOM killer to start, execute echo f > /proc/sysrq -trigger, but

remember that at least one process will be killed. Output will be sent to dmesg.









VII- Memory Reclamition

VIII- IPC

Inter-Process-Communication are mechanisms provided by the kernel to allow processes to communicate with each other.

These are the six primary IPC mechanisms available:

1- Sockets       : Unix Domain Socket(NETLINK ,NETWORK) TCP/IP or UDP sockets to exchange data over the sockets.
2- Pipes         : pipe is used for one way communication of a stream of bytes.
3- Shared Memory : allows one process to share a region of memory in its address space with another. (fastest no  kernel intervention)
4- Semaphores    : locking and synchronization mechanism used most widely when processes share resources.
5- Message Queues: one or more processes can write messages, which can in turn be read by one or more reading processes.
6- Signals       : used to signal asynchronous events to one or more processes (oldest IPC used by Unix systems)

Redhat has 3 methods : Shared Memory, Semaphores, and Message Queues.

kernel parameter
Shared Memory
kernel.shmmax  : /proc/sys/kernel/shmmax : the max allowable size of one shared memory segment in bytes
kernel.shmmni  : /proc/sys/kernel/shmmni : the max number of shared memory segments in the entire system
kernel.shmall  : /proc/sys/kernel/shmall : the max size of shared memory in pages (one page = 4096 bytes for x86/x86_64)

Semaphore
kernel.sem     : /proc/sys/kernel/sem	<SEMMSL> <SEMMNS> <SEMOPM> <SEMMNI>
SEMMSL	the max number of semaphores per identifier
SEMMNS	the max value of a semaphore
SEMOPM	the max number of operations per semaphore call
SEMMNI	the max number of semaphore sets in the entire system

Message Queue
kernel.msgmni /proc/sys/kernel/msgmni	: the number of message queue identifiers
kernel.msgmax /proc/sys/kernel/msgmnb	: the default max size of a message queue in bytes
kernel.msgmnb /proc/sys/kernel/msgmax	: the max size of a message in bytes

ipcmk, ipcs, ipcrm : tools to manuapilite System V interprocess communication (IPC)

ipcmk : create shared memory segment (-M), a semaphore (-S), or a message queue (-Q)
ipcs  : list shared memory segment (-m), a semaphore (-s), or a message queue (-q)
        list limits (-l)
ipcrm : remove shared memory segment (-m), a semaphore (-s), or a message queue (-q)

kernel.threads-max : system-wide maximum number of threads at one time.



